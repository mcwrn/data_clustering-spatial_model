---
title: "assessment_project"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE, paackages}
knitr::opts_chunk$set(echo = TRUE)

install.packages("mlr3measures")
install.packages("pdfCluster")
install.packages("clevr")
install.packages("fpc")
install.packages("dendextend")
install.packages("pdfCluster")
install.packages("poLCA")
install.packages("clustMD")
install.packages("ContaminatedMixt")
install.packages("clustvarsel")
install.packages("flexmix")
install.packages("pgmm")
install.packages("broom")
install.packages("spdep")
install.packages("CARBayes")
install.packages("sp")
install.packages("tinytex")
install.packages("patchwork")
install.packages("RColorBrewer")
```

```{r}
library(tinytex)
library(cluster)
library(mlr3measures)
library(pdfCluster)
library(clevr)
library(fpc)
library(dendextend)
library(mclust)
library(poLCA)
library(clustMD)
library(ContaminatedMixt)
library(clustvarsel)
library(flexmix)
library(pgmm)
library(patchwork)
library(RColorBrewer)
library(tinytex)
```



1. Analysis based on SMR 

```{r cars}


setwd("C:/data_combined")

###.csv files
expected_data=read.csv("expected_counts.csv", header=T, sep=",")
observed_data=read.csv("respiratory_admissions.csv", header=T, sep=",")

expected_data$Id=expected_data$ď.żcode
observed_data$Id=observed_data$ď.żIG


data=merge(expected_data, observed_data, by="Id")
#data=data[,-c(2,5)]

data$SMR2008 <- data$Y2008/data$E2008
data$SMR2009 <- data$Y2009/data$E2009

###shape files
#install.packages("sf")
library(sf)
shape<-read_sf("SG_IntermediateZoneBdry_2001/")
```

```{r}

sf.data <- merge(shape, data, all.x=FALSE, by.x="IZ_CODE", by.y="Id")
plot(sf.data$geometry)

```

Calculating SMR for each year
```{r}
#1


summary(data)

sd_list=list()
for(i in  1:6){
  sd_list[i]=sd(data[,i+1])
}
sd_list


library(sp)
sp.data<-as_Spatial(sf.data)

```
For the purpose of this analysis, we present two plots, each comprising two maps: one for the year 2008 and another for the year 2009. The second plot is overlaid on OpenStreetMap, which may lead to new insights compared to mapping the risk with ggplots.
```{r}

library(ggplot2)
library(broom)
sp.data@data$id <- rownames(sp.data@data)
temp1<-tidy(sp.data)

#temp1<-st_as_sf(sp.dat)
sp.data2 <- merge(temp1, sp.data@data, by = "id")
sp.data2$SMR2008= sp.data2$Y2008/sp.data2$E2008
sp.data2$SMR2009= sp.data2$Y2009/sp.data2$E2009


library(patchwork)
library(RColorBrewer)
```

Creating the first ggplot for SMR2008
```{r}
# 
plot1 <- ggplot(data = sp.data2, aes(x=long, y=lat, group=group, fill = c(SMR2008))) +
  geom_polygon() +
  coord_equal() +
  xlab("Easting (m)") +
  ylab("Northing (m)") +
  labs(title = "SMR for respiratory hospitalisation, year 2008", fill = "SMR") +
  theme(title = element_text(size=16)) +
  scale_fill_gradientn(colors=brewer.pal(n=9, name="YlOrRd"))
```

Creating the second ggplot for SMR2009
```{r}
# 
plot2 <- ggplot(data = sp.data2, aes(x=long, y=lat, group=group, fill = c(SMR2009))) +
  geom_polygon() +
  coord_equal() +
  xlab("Easting (m)") +
  ylab("Northing (m)") +
  labs(title = "SMR for respiratory hospitalisation, year 2009", fill = "SMR") +
  theme(title = element_text(size=16)) +
  scale_fill_gradientn(colors=brewer.pal(n=9, name="YlOrRd"))

```

Arranging the plots side by side
```{r} 
plots_side_by_side <- plot1 + plot2

plots_side_by_side
```

Creating Leaflet maps
```{r}
library(sp)
sp.dat.ll <- spTransform(sp.data, CRS("+proj=longlat +datum=WGS84 +no_defs"))

library(leaflet)
library(htmltools)
colours_2008 <- colorNumeric(palette = "YlOrRd", domain = sp.dat.ll$SMR2008)
colours_2009 <- colorNumeric(palette = "YlOrRd", domain = sp.dat.ll$SMR2009)

# 
map_2008 <- leaflet(data = sp.dat.ll) %>%
  addTiles() %>%
  addPolygons(fillColor = ~colours_2008(SMR2008),
              color = "", weight = 1,
              fillOpacity = 0.7) %>%
  addLegend(pal = colours_2008, values = ~SMR2008,
            opacity = 1, title = "SMR2008") %>%
  addScaleBar(position = "bottomleft")

map_2009 <- leaflet(data = sp.dat.ll) %>%
  addTiles() %>%
  addPolygons(fillColor = ~colours_2009(SMR2009),
              color = "", weight = 1,
              fillOpacity = 0.7) %>%
  addLegend(pal = colours_2009, values = ~SMR2009,
            opacity = 1, title = "SMR2009") %>%
  addScaleBar(position = "bottomleft")


maps_side_by_side <- tagList(map_2008, map_2009)
maps_side_by_side

```

The main conclusions are ........

We also present the analysis spatial autocorrelation in each of the years by using Moran's I statistic.

```{r}
##spatial autocorrelation
library(spdep)
W.nb <- poly2nb(sf.data, row.names = rownames(sf.data))

summary(W.nb)
W <- nb2mat(W.nb, style = "B")
?nb2mat
W.list <- nb2listw(W.nb, style = "B")
?nb2listw

sf.data$SMR2008= sf.data$Y2008/sf.data$E2008
sf.data$SMR2009= sf.data$Y2009/sf.data$E2009

moran.mc(x = sf.data$SMR2008, listw = W.list, nsim = 10000)
```
We conclude that I statistic equals to 0.404 and is significantly different from independence, thus it provides evidence that there is spatial autocorrelation in the SMR2008 variable
```{r}
moran.mc(x = sf.data$SMR2009, listw = W.list, nsim = 10000)
```
We conclude that I statistic equals to 0.39 and is significantly different from independence, thus it provides evidence that there is spatial autocorrelation in the SMR2009s variable


2. Leroux model

```{r}
formula2008 <- Y2008 ~ offset(log(E2008)) 
formula2009 <- Y2009 ~ offset(log(E2009))

library(CARBayes)
model2008 <- S.CARleroux(formula=formula2008, family="poisson", data=sf.data, W=W,
burnin=10000, n.sample=100000, thin=10, verbose=FALSE)
print(model2008)

model2009 <- S.CARleroux(formula=formula2009, family="poisson", data=sf.data, W=W,
burnin=10000, n.sample=100000, thin=10, verbose=FALSE)
print(model2009)
```

summaries examining convergence of the chain and comment on them. Plot the fitted values on two maps and comment on them
```{r}
plot(model2008$samples$rho)
plot(model2008$fitted.values)
summary(model2008)


plot(model2009$samples$rho)
plot(model2009$fitted.values)
summary(model2009)
```


Assessing goodness of fit
```{r}

moran.mc(x = residuals(model2008, type="pearson"), listw = W.list, nsim = 10000)
moran.mc(x = residuals(model2009, type="pearson"), listw = W.list, nsim = 10000)
```

The statistic and accompanying p-value suggest there is no spatial correlation remaining in the residuals from this model, indicating that the spatial CAR model has adequately removed the correlation from the data.


3. Bivariate mixture model
```{r}
summary(cars)

########################################
#Clustering simulated data using clustMD
########################################


f.v2008=model2008$fitted.values
f.v2009=model2009$fitted.values
fitted_values=cbind(f.v2008,f.v2009)
#load the clustMD library
#install.packages("clustMD")
library(clustMD)

#Specify variance parameterisations to be used - here all
methods = c("EII", "VII", "EEI", "VEI", "EVI", "VVI")
#Set the range of the number of clusters
clust.range<-c(1:7)

#DON'T RUN, takes a few minutes!
# Initializing storage of the BIC
mds.bic = matrix(NA, nrow = length(clust.range), ncol = length(methods))

# Looping through the 6 variance parameterizations for 1:4 classes (saving BIC) 

#for(m in methods){
#  for(g in clust.range){
#    mds.bic[g, which(methods==m)] = clustMD(fitted_values, G = g, CnsIndx = 2, OrdIndx = 2, Nnorms = 100, MaxIter = 500, model = m, scale = FALSE)$BIChat
#  }
#}

#Plot the BIC values for the range of number of clusters with a different line for each variance parameterisation
plot(clust.range, mds.bic[,1], type = "b", pch = 1, xlab = "Number of Clusters", ylab = "BIC", main = "", xaxt = "n")
axis(1, at = clust.range, labels = clust.range)
lines(clust.range, mds.bic[,2], type = "b", pch = 2, col = 2)
lines(clust.range, mds.bic[,3], type = "b", pch = 3, col = 3)
lines(clust.range, mds.bic[,4], type = "b", pch = 4, col = 4)
lines(clust.range, mds.bic[,5], type = "b", pch = 5, col = 5)
lines(clust.range, mds.bic[,6], type = "b", pch = 6, col = 6)
legend("bottomright", c("EII", "VII", "EEI", "VEI", "EVI", "VVI"), col = 1:6, pch = 1:6, ncol = 2)

# Fitting the model with the highest BIC
md.min = clustMD(fitted_values, G = 5, CnsIndx = 2, OrdIndx = 2, Nnorms = 100, MaxIter = 500, model = "VII", scale = FALSE)
#?clustMD
# Produce cross-classification table between true classes and assigned clusters
#cl
md.min$cl
#table(cl, md.min$cl)

#Compare the cluster result with the the truth
library(mclust)
#adjustedRandIndex(cl, md.min$cl)

#Plot the data with the clusters labelled by colour
library(MASS)
eqscplot(fitted_values[,1:2], col = md.min$cl, pch = 18)
?eqscplot


#ggplot(fitted_values$f.v2008, fitted_values$f.v2009, color =  )

## Including Plots

#You can also embed plots, for example:

d1<-dist(fitted_values)
si1<-silhouette(md.min$cl,d1)
ave.silh1<-mean(si1[,3])
ave.silh1
```

k-means algorithm


```{r}


#Check for outliers using single linkage
single.res <- hclust(dist(fitted_values),"single")
plot(single.res)

#Look if cutting tree identifies singletons joining later
temp<-cutree(single.res,k=5)

table(temp)

#Remove the four singleton outliers (only keep observations in clusters 1 or 2 from temp)
new.SMR<-as.matrix(fitted_values[temp==1])
new.SMR

#Run k-means for k from 2 to 10 and record the total within cluster sums of squares for each
res.kmeans.twss<-rep(NA,10)
n<-length(new.SMR)
res.kmeans.twss[1]<-sum((n-1)*apply(new.SMR,2,var))

for(i in 2:10)
{
  res.kmeans.twss[i]<-kmeans(new.SMR,centers=i, nstart=30)$tot.withinss
}

# Plot the elbow graph
plot(c(1:10),res.kmeans.twss,type="b")

# Calculate and plot the gap statistic
gap.kmeans<-clusGap(as.matrix(new.SMR), FUN=kmeans, nstart=30,K.max=10,B=100)
plot(gap.kmeans)

# Calculate the average silhouette width for each k and find the best k
ave.silh<-rep(NA,120)
d<-dist(new.SMR)
length(new.SMR)
for(i in 2:120)
{
  res.kmeans<-kmeans(new.SMR,centers=i, nstart=100)
  si<-silhouette(res.kmeans$cluster,d)
  ave.silh[i]<-mean(si[,3])
}
ave.silh
ave.silh[2]
plot(ave.silh)
#Compare the 2 cluster k-means solution on the Multipe Crime data to the 4 clusters solution

kmeans.2<-kmeans(new.SMR,2,nstart=30)
kmeans.3<-kmeans(new.SMR,3,nstart=30)
?kmeans

#Take a look at the 3-cluster k-medoids clustering and compare it too
library(cluster)
pam.2<-pam(new.SMR,2)
plot(pam.2)

# Calculate the average silhouette width for each k and find the best k
ave.silh2<-rep(NA,30)
d<-dist(new.SMR)
length(new.SMR)


si2<-silhouette(pam.2$clust,d)
ave.silh2<-mean(si2[,3])

ave.silh2



#cl1<-c(rep(1,109),rep(2,108))
#cl2<-c(rep(1,55),rep(2,54),rep(3,54),rep(4,54))

```

comparing the results

```{r}
#ASW for k-means with 3 clusters
ave.silh[2]

#ASW for k-medoids with 3 clusters
ave.silh2

#ASW for Mixture Clustering 
ave.silh1

```
We see that Average Silhouette Width for 3-means algorithm is the highest, so it is the best algorithm for clustering the mean fitted values SMR data.  
